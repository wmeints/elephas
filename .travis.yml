language: python
python:
  # We don't actually use the Travis Python, but this keeps it organized.
  - "2.6"
  - "2.7"
  - "3.3"
  - "3.4"
before_install:
  - sudo apt-get update
  # We do this conditionally because it saves us some downloading if the
  # version is the same.
  - if [[ "$TRAVIS_PYTHON_VERSION" == "2.7" ]]; then
      wget https://repo.continuum.io/miniconda/Miniconda2-latest-Linux-x86_64.sh -O miniconda.sh;
    else
      wget https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh -O miniconda.sh;
    fi
  - bash miniconda.sh -b -p $HOME/miniconda
  - export PATH="$HOME/miniconda/bin:$PATH"
  - hash -r
  - conda config --set always_yes yes --set changeps1 no
  - conda update -q conda
  # Useful for debugging any issues with conda
  - conda info -a
  
install:
  - conda create -q -n test-environment python=$TRAVIS_PYTHON_VERSION numpy scipy matplotlib pandas pytest h5py flask pip
  - source activate test-environment
  - pip install pytest-cov python-coveralls
  - pip install git+git://github.com/Theano/Theano.git
  - pip install keras
  - python setup.py install

  # Install Spark
  - wget http://apache.mirrors.tds.net/spark/spark-1.5.2/spark-1.5.2-bin-hadoop2.6.tgz -P $HOME
  - tar zxvf $HOME/spark-* -C $HOME
  - export SPARK_HOME=$HOME/spark-1.5.2-bin-hadoop2.6
  - export PATH=$PATH:$SPARK_HOME/bin

# Just run an example for now
script:
  - python -c "import keras.backend"
  - spark-submit --driver-memory 2G $PWD/examples/mnist_mlp_spark.py
after_success:
  - coveralls
